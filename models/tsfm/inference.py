"""Chronos-based time series forecasting inference engine."""
import time
import numpy as np
from typing import Optional, Dict, Any, List
import logging

from .schemas import ForecastInput, ForecastOutput, BatchForecastInput, BatchForecastOutput
from .forecast_utils import forecast_series

logger = logging.getLogger(__name__)


class ChronosInferenceEngine:
    """
    Inference engine for Amazon Chronos time series forecasting model.
    
    This class handles model loading, preprocessing, and probabilistic forecast generation.
    """
    
    def __init__(
        self,
        model_name: str = "amazon/chronos-t5-tiny",
        device: Optional[str] = None,
        quantize: bool = False,
        deterministic_mode: bool = False
    ):
        """
        Initialize the Chronos inference engine.
        
        Args:
            model_name: HuggingFace model identifier (e.g., "amazon/chronos-t5-tiny")
            device: Device to run on ("cpu", "cuda", "mps", or None for auto)
            quantize: Whether to use quantized model (faster, less accurate)
            deterministic_mode: If True, use deterministic inference (same inputs â†’ same outputs)
        """
        self.model_name = model_name
        self.device = device if not deterministic_mode else "cpu"  # Force CPU for determinism
        self.quantize = quantize and not deterministic_mode  # No quantization in deterministic mode
        self.deterministic_mode = deterministic_mode
        self.model = None
        self.tokenizer = None
        self.pipeline = None
        self._initialized = False
        
        if deterministic_mode:
            from models.deterministic_mode import DeterministicForecastMode
            self.dfm = DeterministicForecastMode(enabled=True)
            logger.info("Deterministic Forecast Mode (DFM) enabled")
        else:
            self.dfm = None
        
    def _initialize_model(self) -> None:
        """Lazy initialization of the Chronos model."""
        if self._initialized:
            return
            
        logger.info(f"Initializing Chronos model: {self.model_name}")
        start_time = time.time()
        
        try:
            # Try to import chronos_forecasting
            # If not installed, will fall back to mock mode
            try:
                from chronos import ChronosPipeline
                
                # Initialize pipeline
                if self.deterministic_mode:
                    # Deterministic mode: use float64, CPU only
                    torch_dtype = "float64"
                    device_map = "cpu"
                else:
                    torch_dtype = "float16" if self.quantize else "float32"
                    device_map = self.device or "auto"
                
                self.pipeline = ChronosPipeline.from_pretrained(
                    self.model_name,
                    device_map=device_map,
                    torch_dtype=torch_dtype
                )
                
                # Set deterministic flag on pipeline for forecast_utils
                if self.deterministic_mode:
                    self.pipeline._deterministic_mode = True
                
                logger.info(f"Chronos model loaded successfully in {time.time() - start_time:.2f}s")
                self._initialized = True
                
            except ImportError:
                logger.warning(
                    "chronos-forecasting not installed. Using mock mode. "
                    "Install with: pip install git+https://github.com/amazon-science/chronos-forecasting.git"
                )
                self._initialized = True  # Mark as initialized to use mock
                
        except Exception as e:
            logger.error(f"Failed to initialize Chronos model: {e}", exc_info=True)
            raise RuntimeError(f"Model initialization failed: {e}")
    
    def _prepare_context(self, series: List[float], context_length: Optional[int]) -> np.ndarray:
        """
        Prepare input context from historical series.
        
        Args:
            series: Historical time series values
            context_length: Number of points to use (None = use all)
            
        Returns:
            Numpy array of context values
        """
        # Use deterministic mode preparation if enabled
        if self.dfm:
            return self.dfm.prepare_context(series, context_length)
        
        # Standard preparation
        dtype = np.float64 if self.deterministic_mode else np.float32
        series_array = np.array(series, dtype=dtype)
        
        # Handle NaN/inf values
        if np.any(np.isnan(series_array)) or np.any(np.isinf(series_array)):
            logger.warning("Series contains NaN/Inf values. Filling with forward-fill.")
            series_array = np.nan_to_num(series_array, nan=np.nanmean(series_array), 
                                        posinf=np.nanmax(series_array), 
                                        neginf=np.nanmin(series_array))
        
        # Select context window (deterministic: always use same slice)
        if context_length is not None:
            context = series_array[-context_length:].copy()
        else:
            context = series_array.copy()
        
        # Ensure minimum length
        if len(context) < 10:
            logger.warning(f"Context length ({len(context)}) is very short. May affect forecast quality.")
        
        return context
    
    def _generate_realistic_mock_forecast(
        self,
        series: List[float],
        forecast_horizon: int
    ) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        Generate a realistic mock forecast when Chronos is not available.
        
        Uses simple statistical methods to create plausible forecasts with uncertainty.
        """
        series_array = np.array(series)
        
        # Simple trend + seasonality estimation
        n = len(series_array)
        recent_window = min(50, n)
        recent_values = series_array[-recent_window:]
        
        # Estimate trend (linear regression on recent values)
        x = np.arange(len(recent_values))
        trend_coef = np.polyfit(x, recent_values, 1)
        trend = trend_coef[0]
        
        # Estimate volatility (rolling std)
        volatility = np.std(recent_values)
        
        # Generate point forecast (extrapolate trend)
        last_value = series_array[-1]
        point_forecast = []
        for h in range(forecast_horizon):
            # Trend component
            trend_value = last_value + trend * (h + 1)
            # Add some mean reversion
            mean_reversion = (np.mean(recent_values) - last_value) * 0.1 * (h + 1) / forecast_horizon
            point_forecast.append(trend_value + mean_reversion)
        
        point_forecast = np.array(point_forecast)
        
        # Generate uncertainty bounds (wider for longer horizons)
        confidence_scale = 1.96  # ~95% interval for normal distribution
        horizon_multiplier = 1 + (np.arange(forecast_horizon) / forecast_horizon) * 0.5
        
        lower_bound = point_forecast - confidence_scale * volatility * horizon_multiplier
        upper_bound = point_forecast + confidence_scale * volatility * horizon_multiplier
        
        return point_forecast, lower_bound, upper_bound
    
    def forecast(
        self,
        input_data: ForecastInput,
        num_samples: int = 100,
        temperature: float = 1.0
    ) -> ForecastOutput:
        """
        Generate probabilistic forecast for a single time series.
        
        Args:
            input_data: ForecastInput with series and forecast_horizon
            num_samples: Number of Monte Carlo samples for uncertainty estimation
            temperature: Sampling temperature (higher = more diverse samples)
            
        Returns:
            ForecastOutput with point forecast and uncertainty bounds
        """
        if not self._initialized:
            self._initialize_model()
        
        start_time = time.time()
        
        # Prepare context
        context = self._prepare_context(
            input_data.series,
            input_data.context_length
        )
        
        forecast_horizon = input_data.forecast_horizon
        
        # Generate forecast
        if self.pipeline is not None:
            # REAL CHRONOS INFERENCE
            try:
                point_forecast, lower_bound, upper_bound = forecast_series(
                    model=self.pipeline,
                    series=input_data.series,
                    forecast_horizon=forecast_horizon,
                    context_length=input_data.context_length
                )
                logger.info("Using real Chronos model for inference")
            except Exception as e:
                logger.warning(f"Chronos inference failed, falling back to mock: {e}")
                # Fallback to mock if Chronos fails
                point_forecast, lower_bound, upper_bound = self._generate_realistic_mock_forecast(
                    input_data.series,
                    forecast_horizon
                )
        else:
            # REALISTIC MOCK MODE (when library not installed)
            point_forecast, lower_bound, upper_bound = self._generate_realistic_mock_forecast(
                input_data.series,
                forecast_horizon
            )
        
        inference_time_ms = (time.time() - start_time) * 1000
        
        # Build output
        output = ForecastOutput(
            point_forecast=point_forecast.tolist(),
            lower_bound=lower_bound.tolist(),
            upper_bound=upper_bound.tolist(),
            forecast_horizon=forecast_horizon,
            model_name=self.model_name,
            inference_time_ms=inference_time_ms,
            metadata=input_data.metadata
        )
        
        logger.info(
            f"Generated forecast: horizon={forecast_horizon}, "
            f"time={inference_time_ms:.1f}ms"
        )
        
        return output
    
    def forecast_batch(
        self,
        input_data: BatchForecastInput,
        num_samples: int = 100,
        temperature: float = 1.0
    ) -> BatchForecastOutput:
        """
        Generate forecasts for multiple time series in batch.
        
        Args:
            input_data: BatchForecastInput with list of series
            num_samples: Number of Monte Carlo samples per series
            temperature: Sampling temperature
            
        Returns:
            BatchForecastOutput with forecasts for all series
        """
        if not self._initialized:
            self._initialize_model()
        
        start_time = time.time()
        
        forecasts = []
        for i, series in enumerate(input_data.series_list):
            metadata = None
            if input_data.metadata_list and i < len(input_data.metadata_list):
                metadata = input_data.metadata_list[i]
            
            forecast_input = ForecastInput(
                series=series,
                forecast_horizon=input_data.forecast_horizon,
                context_length=input_data.context_length,
                metadata=metadata
            )
            
            forecast = self.forecast(
                forecast_input,
                num_samples=num_samples,
                temperature=temperature
            )
            forecasts.append(forecast)
        
        total_time_ms = (time.time() - start_time) * 1000
        
        return BatchForecastOutput(
            forecasts=forecasts,
            total_inference_time_ms=total_time_ms
        )
    
    def __enter__(self):
        """Context manager entry."""
        self._initialize_model()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit (cleanup if needed)."""
        # Model cleanup if necessary
        pass

